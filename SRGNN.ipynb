{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(2020)\n",
    "# set cuda\n",
    "gpu = 0\n",
    "use_cuda = gpu >= 0 and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    device = torch.device(\"cuda\", gpu)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "logging.info(\"Use cuda: %s, gpu id: %d.\", use_cuda, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将train_data和test_data读取存入list中\n",
    "def ReadTxtName(rootdir):\n",
    "    lines = []\n",
    "    with open(rootdir, 'r') as file_to_read:\n",
    "        while True:\n",
    "            line = file_to_read.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip('\\n')\n",
    "            line = list(eval(line))\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data_example/train_data.txt'\n",
    "test_data_path = 'data_example/test_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ReadTxtName(train_data_path)\n",
    "test_set = ReadTxtName(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['user_id', 'item_seq_temp','cat_list','time_list','time_last_list','time_now_list','position_list','target','item_seq_len'],data = train_set)\n",
    "test_data = pd.DataFrame(columns=['user_id', 'item_seq_temp','cat_list','time_list','time_last_list','time_now_list','position_list','target','item_seq_len'],data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118873, 190989, 73693, 354311, 73693, 354311,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298668, 297576, 305398, 107015, 32892, 76809,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211347, 153658, 7223, 81509, 19699, 81509, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95057, 68099, 161481, 366635, 150257, 303230,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228127, 202790, 37771, 210693, 316530, 186423...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118873, 190989, 73693, 354311, 73693, 354311,...   \n",
       "1     3839  [298668, 297576, 305398, 107015, 32892, 76809,...   \n",
       "2     3719  [211347, 153658, 7223, 81509, 19699, 81509, 10...   \n",
       "3     4362  [95057, 68099, 161481, 366635, 150257, 303230,...   \n",
       "4     1104  [228127, 202790, 37771, 210693, 316530, 186423...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  \n",
       "0            26  \n",
       "1            23  \n",
       "2            17  \n",
       "3            19  \n",
       "4            18  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_seq_len'] = train_data['item_seq_len']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118873, 190989, 73693, 354311, 73693, 354311,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298668, 297576, 305398, 107015, 32892, 76809,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211347, 153658, 7223, 81509, 19699, 81509, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95057, 68099, 161481, 366635, 150257, 303230,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228127, 202790, 37771, 210693, 316530, 186423...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118873, 190989, 73693, 354311, 73693, 354311,...   \n",
       "1     3839  [298668, 297576, 305398, 107015, 32892, 76809,...   \n",
       "2     3719  [211347, 153658, 7223, 81509, 19699, 81509, 10...   \n",
       "3     4362  [95057, 68099, 161481, 366635, 150257, 303230,...   \n",
       "4     1104  [228127, 202790, 37771, 210693, 316530, 186423...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  \n",
       "0            25  \n",
       "1            22  \n",
       "2            16  \n",
       "3            18  \n",
       "4            17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_seq_temp'] = train_data.item_seq_temp.apply(lambda x:[i+1 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 32762.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_data))):\n",
    "    train_data['item_seq_temp'][i][train_data.item_seq_len[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 50\n",
    "train_data['item_seq_temp'] = train_data['item_seq_temp'].apply(lambda x:x+[0]*(input_length-len(x))if len(x)<input_length else x[:input_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对train_data和test_data进行padding,即item_count+1作为padding_idx\n",
    "# item_id,user_id,cat_list_id进行了重新编码\n",
    "train_data['target_item'] = train_data['target'].apply(lambda x:x[0]) \n",
    "test_data['target_item'] = test_data['target'].apply(lambda x:x[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "      <th>target_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118874, 190990, 73694, 354312, 73694, 354312,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>25</td>\n",
       "      <td>125165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298669, 297577, 305399, 107016, 32893, 76810,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>22</td>\n",
       "      <td>168523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211348, 153659, 7224, 81510, 19700, 81510, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>16</td>\n",
       "      <td>329307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95058, 68100, 161482, 366636, 150258, 303231,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>18</td>\n",
       "      <td>146956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228128, 202791, 37772, 210694, 316531, 186424...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>17</td>\n",
       "      <td>111155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118874, 190990, 73694, 354312, 73694, 354312,...   \n",
       "1     3839  [298669, 297577, 305399, 107016, 32893, 76810,...   \n",
       "2     3719  [211348, 153659, 7224, 81510, 19700, 81510, 10...   \n",
       "3     4362  [95058, 68100, 161482, 366636, 150258, 303231,...   \n",
       "4     1104  [228128, 202791, 37772, 210694, 316531, 186424...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  target_item  \n",
       "0            25       125165  \n",
       "1            22       168523  \n",
       "2            16       329307  \n",
       "3            18       146956  \n",
       "4            17       111155  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_data = torch.LongTensor(train_data['item_seq_temp'][:5])\n",
    "mask = torch.gt(sequence_data, 0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随便padding\n",
    "def pad(data):\n",
    "    for i in data.columns:\n",
    "        if i =='cat_list':\n",
    "            data[i] = data[i].apply(lambda x:x+[x[-1]-1]*(input_length-len(x))if len(x)<input_length else x[:input_length])\n",
    "        elif i=='position_list':\n",
    "            data[i] = data[i].apply(lambda x:[i for i in range(input_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_length = 50\n",
    "pad(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得train_data和test_data\n",
    "columns = ['user_id','item_seq_temp','cat_list','position_list','item_seq_len','target_item']\n",
    "train_data= train_data[columns]\n",
    "test_data = test_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方便处理数据，转换为numpy格式\n",
    "user_id = np.array(train_data['user_id'].tolist(),dtype = np.int32)\n",
    "item_seq_temp = np.array(train_data['item_seq_temp'].tolist(),dtype = np.int32)\n",
    "cat_list = np.array(train_data['cat_list'].tolist(),dtype = np.int32)\n",
    "position_list = np.array(train_data['position_list'].tolist(),dtype = np.int32)\n",
    "item_seq_len = np.array(train_data['item_seq_len'].tolist(),dtype = np.int64)\n",
    "target_item = np.array(train_data['target_item'].tolist(),dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_user_id,x_item_seq_temp,x_cat_list,x_position_list,x_item_seq_len,y,batch_size,shuffle = True):\n",
    "    assert x_user_id.shape[0] == y.shape[0]\n",
    "    if shuffle:\n",
    "        shuffled_index = np.random.permutation(y.shape[0])\n",
    "        x_user_id,x_item_seq_len,x_cat_list,x_position_list,x_item_seq_len = x_user_id[shuffled_index],x_item_seq_len[shuffled_index],x_cat_list[shuffled_index],x_position_list[shuffled_index],x_item_seq_len[shuffled_index]\n",
    "        y = y[shuffled_index]\n",
    "    \n",
    "    n_batches = int(x_user_id.shape[0]/batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        x_user_id_batch = x_user_id[i*batch_size:(i+1)*batch_size]\n",
    "        x_item_seq_temp_batch = x_item_seq_temp[i*batch_size:(i+1)*batch_size]\n",
    "        x_cat_list_batch = x_cat_list[i*batch_size:(i+1)*batch_size]\n",
    "        x_position_list_batch = x_position_list[i*batch_size:(i+1)*batch_size]\n",
    "        x_item_seq_len_batch = x_item_seq_len[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield x_user_id_batch,x_item_seq_temp_batch,x_cat_list_batch,x_position_list_batch,x_item_seq_len_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "test_seq = torch.LongTensor([2,3,4,5,6,0,0])\n",
    "for _,data in enumerate(test_seq):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 15.559103012084961\n",
      "1 0 7.459601402282715\n",
      "2 0 7.270878791809082\n",
      "3 0 6.845137119293213\n",
      "4 0 7.058331489562988\n",
      "5 0 6.960624694824219\n",
      "6 0 7.042585849761963\n",
      "7 0 7.051896572113037\n",
      "8 0 6.9353346824646\n",
      "9 0 6.9046807289123535\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "def get_slice(x_item_seq_temp_batch, x_item_seq_len_batch, y_batch, mask_batch):\n",
    "        items, n_node, A, alias_inputs = [], [], [], []\n",
    "        max_n_node = x_item_seq_temp_batch.shape[1]\n",
    "        x_item_seq_temp_batch = x_item_seq_temp_batch.numpy()\n",
    "        x_item_seq_len_batch = x_item_seq_len_batch.numpy()\n",
    "        y_batch = y_batch.numpy()\n",
    "        mask_batch = mask_batch.numpy()\n",
    "        for u_input in x_item_seq_temp_batch:\n",
    "            node = np.unique(u_input)\n",
    "            items.append(node.tolist() + (max_n_node - len(node))* [0])\n",
    "            u_A = np.zeros((max_n_node, max_n_node))\n",
    "            \n",
    "            for i in np.arange(len(u_input) - 1):\n",
    "                \n",
    "                if u_input[i + 1] == 0:\n",
    "                    break\n",
    "                \n",
    "                u = np.where(node == u_input[i])[0][0]\n",
    "                v = np.where(node == u_input[i + 1])[0][0]\n",
    "                u_A[u][v] = 1\n",
    "            u_sum_in = np.sum(u_A, 0)\n",
    "            u_sum_in[np.where(u_sum_in == 0)] = 1\n",
    "            u_A_in = np.divide(u_A, u_sum_in)\n",
    "            u_sum_out = np.sum(u_A, 1)\n",
    "            u_sum_out[np.where(u_sum_out == 0)] = 1\n",
    "            u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
    "            u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
    "            A.append(u_A)\n",
    "            alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
    "\n",
    "        return alias_inputs, A, items, mask_batch, y_batch\n",
    "\n",
    "    \n",
    "for epoch in range(10):\n",
    "    for batch_idx,data in enumerate(get_batch(user_id,item_seq_temp,cat_list,position_list,item_seq_len,target_item,batch_size)):\n",
    "#         x_user_id_batch = torch.LongTensor(data[0])\n",
    "        x_item_seq_temp_batch = torch.LongTensor(data[1])\n",
    "#         x_cat_list_batch = torch.LongTensor(data[2])\n",
    "#         x_position_list_batch = torch.LongTensor(data[3])\n",
    "        x_item_seq_len_batch = torch.LongTensor(data[4])\n",
    "        y_batch = torch.LongTensor(data[5])\n",
    "        mask_batch = x_item_seq_temp_batch.gt(0)\n",
    "        alias_inputs, A, items, mask_batch, y_batch = get_slice(x_item_seq_temp_batch, x_item_seq_len_batch, y_batch, mask_batch)\n",
    "        \n",
    "        alias_inputs = torch.Tensor(alias_inputs).long()\n",
    "        items = torch.Tensor(items).long()\n",
    "        A = torch.Tensor(A).float()\n",
    "        mask_batch = torch.Tensor(mask_batch).long()\n",
    "        y_batch = torch.Tensor(y_batch).long()\n",
    "        \n",
    "        \n",
    "        \n",
    "        hidden = model(items, A)\n",
    "        alias_inputs = alias_inputs.view(-1, alias_inputs.shape[1],1).expand(-1, -1, embedding_dim)\n",
    "#         print(alias_inputs.size())\n",
    "#         print(hidden.size())\n",
    "        seq_hidden = torch.gather(hidden, dim=1, index=alias_inputs)\n",
    "        \n",
    "        pre_emb, item_li
    _emb_weight = model.compute_scores(seq_hidden, mask_batch, x_item_seq_len_batch)\n",
    "        loss = criterion(item_list_emb_weight,pre_emb,y_batch)\n",
    "        train_loss.append(loss.item())\n",
    "        # Backward and optimizer\n",
    "        # 1.优化器保存先前的梯度信息\n",
    "        optimizer.zero_grad()\n",
    "        # 2.计算梯度\n",
    "        loss.backward()\n",
    "#         3.梯度更新 w' = w - lr*grads\n",
    "        optimizer.step()\n",
    "        if batch_idx%200 == 0:\n",
    "            print(epoch,batch_idx,loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbedding(nn.Module):\n",
    "    def __init__(self,parameter_path,input_length,embedding_dim):\n",
    "        super(GetEmbedding,self).__init__()\n",
    "        self.parameter_path = parameter_path\n",
    "        self.parameters = self.get_parameter(self.parameter_path)\n",
    "        self.user_count = self.parameters['user_count']\n",
    "        self.item_count = self.parameters['item_count']\n",
    "        self.category_count = self.parameters['category_count']\n",
    "        self.input_length = input_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_id_embedding = nn.Embedding(self.user_count+3,self.embedding_dim)\n",
    "        self.item_list_embedding = nn.Embedding(self.item_count+3,self.embedding_dim,padding_idx = 0)\n",
    "        self.item_list_embedding_weight = self.item_list_embedding.weight\n",
    "        self.category_list_embedding = nn.Embedding(self.category_count+3,self.embedding_dim)\n",
    "        self.position_list_embeddig = nn.Embedding(self.input_length,self.embedding_dim)\n",
    "        self.apply(self.init_weights)\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        \n",
    "    def get_parameter(self,file_path):\n",
    "        with open(file_path, 'rb') as f:  \n",
    "            parameters = pickle.loads(f.read())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, embedding_size, step=1):\n",
    "        super(GNN, self).__init__()\n",
    "        self.step = step\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_size = embedding_size * 2\n",
    "        self.gate_size = embedding_size * 3\n",
    "        self.w_ih = nn.Parameter(torch.Tensor(self.gate_size, self.input_size))\n",
    "        self.w_hh = nn.Parameter(torch.Tensor(self.gate_size, self.embedding_size))\n",
    "        self.b_ih = nn.Parameter(torch.Tensor(self.gate_size))\n",
    "        self.b_hh = nn.Parameter(torch.Tensor(self.gate_size))\n",
    "        self.b_iah = nn.Parameter(torch.Tensor(self.embedding_size))\n",
    "        self.b_oah = nn.Parameter(torch.Tensor(self.embedding_size))\n",
    "        self.linear_edge_in = nn.Linear(self.embedding_size, self.embedding_size, bias=True)\n",
    "        self.linear_edge_out = nn.Linear(self.embedding_size, self.embedding_size, bias=True)\n",
    "    def GNNCell(self, A, hidden):\n",
    "#         (batch_size, max_session_len, max_session_len) * (batch_size, max_session_len, embedding_size)\n",
    "        input_in = torch.matmul(A[:, :, :A.shape[1]], self.linear_edge_in(hidden)+self.b_iah)\n",
    "#        (batch_size, max_session_len, max_session_len) * (batch_size, max_session_len, embedding_size)\n",
    "        input_out = torch.matmul(A[:, :, A.shape[1]:2 * A.shape[1]], self.linear_edge_out(hidden)+self.b_oah)\n",
    "        \n",
    "#         inputs.shape :(batch_size, max_session_len, embedding_size * 2)\n",
    "        inputs = torch.cat([input_in, input_out], 2)\n",
    "#         gi.shape = gh.shape:(batch_size, max_session_len, embedding_zie * 3)\n",
    "        gi = F.linear(inputs, self.w_ih, self.b_ih)\n",
    "        gh = F.linear(hidden, self.w_hh, self.b_hh)\n",
    "        \n",
    "#     i_r.shape = i_i.shape = i_n.shape :(batch_size, max_session_len, hidden_size)\n",
    "        i_r, i_i, i_n = gi.chunk(3, 2)\n",
    "        h_r, h_i, h_n = gi.chunk(3, 2)\n",
    "        \n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        input_gate = torch.sigmoid(i_i + h_i)\n",
    "        \n",
    "        new_gate = torch.tanh(i_n + reset_gate * h_n)\n",
    "        hy = (1- input_gate) * hidden + input_gate * new_gate\n",
    "        return hy\n",
    "    \n",
    "    def forward(self, A, hidden):\n",
    "        for i in range(self.step):\n",
    "            hidden = self.GNNCell(A, hidden)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionGraph(nn.Module):\n",
    "    def __init__(self, parameter_path,input_length,embedding_size, step):\n",
    "        super(SessionGraph, self).__init__()\n",
    "        self.parameter_path = parameter_path\n",
    "        self.input_length = input_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.step = step\n",
    "        self.emb = GetEmbedding(self.parameter_path,self.input_length,self.embedding_size)\n",
    "        self.gnn = GNN(self.embedding_size, self.step)\n",
    "        self.linear_one = nn.Linear(self.embedding_size, self.embedding_size, bias = True)\n",
    "        self.linear_two = nn.Linear(self.embedding_size, self.embedding_size, bias=True)\n",
    "        self.linear_three = nn.Linear(self.embedding_size, 1, bias=False)\n",
    "        self.linear_transform = nn.Linear(self.embedding_size * 2, self.embedding_size, bias=True)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0/math.sqrt(self.embedding_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "            \n",
    "    def forward(self, inputs, A):\n",
    "        hidden = self.emb.item_list_embedding(inputs)\n",
    "        hidden = self.gnn(A, hidden)\n",
    "        return hidden\n",
    "    \n",
    "    def gather_indexes(self, output, gather_index):\n",
    "        \"Gathers the vectors at the spexific positions over a minibatch\"\n",
    "        gather_index = gather_index.view(-1, 1, 1).expand(-1, -1, self.embedding_size)\n",
    "        output_tensor = output.gather(dim=1, index=gather_index)\n",
    "        return output_tensor.squeeze(1)     \n",
    "    \n",
    "    def compute_scores(self, hidden, mask, seq_len_batch):\n",
    "        ht = self.gather_indexes(hidden, seq_len_batch - 1)\n",
    "        q1 = self.linear_one(ht).view(ht.shape[0], 1, ht.shape[1])\n",
    "        q2 = self.linear_two(hidden)\n",
    "        \n",
    "        alpha = self.linear_three(torch.sigmoid(q1 + q2))\n",
    "#         print('alpha.size', alpha.size())\n",
    "#         print('hidden.size', hidden.size())\n",
    "#         print('mask.size',mask.size())\n",
    "        a = torch.sum(alpha * hidden * mask.view(mask.shape[0], -1, 1).float(), 1)\n",
    "        pre_emb = self.linear_transform(torch.cat([a, ht], dim = 1))\n",
    "        return pre_emb, self.emb.item_list_embedding_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "parameter_path = 'data_example/parameters.pkl'\n",
    "input_length = 50\n",
    "embedding_dim = 32\n",
    "hidden_size=16\n",
    "step = 1\n",
    "\n",
    "model = SessionGraph(parameter_path,input_length,embedding_dim,step = 1)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "criterion = Myloss()\n",
    "train_loss = []\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Myloss,self).__init__()\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "    def forward(self,emb,pred,truth):\n",
    "        item_lookup_table_T = emb.t()\n",
    "        logits = torch.matmul(pred,item_lookup_table_T)\n",
    "        log_probs = self.log_softmax(logits)\n",
    "        truth = torch.reshape(truth,[-1])\n",
    "        one_hot_labels = F.one_hot(truth, num_classes=emb.shape[0])\n",
    "        loss_origin = -torch.sum(log_probs.float() * one_hot_labels.float(), dim=-1)\n",
    "        loss = torch.mean(loss_origin)\n",
    "        return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
