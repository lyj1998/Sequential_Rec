{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(2020)\n",
    "# set cuda\n",
    "gpu = 0\n",
    "use_cuda = gpu >= 0 and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    device = torch.device(\"cuda\", gpu)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "logging.info(\"Use cuda: %s, gpu id: %d.\", use_cuda, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将train_data和test_data读取存入list中\n",
    "def ReadTxtName(rootdir):\n",
    "    lines = []\n",
    "    with open(rootdir, 'r') as file_to_read:\n",
    "        while True:\n",
    "            line = file_to_read.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip('\\n')\n",
    "            line = list(eval(line))\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data_example/train_data.txt'\n",
    "test_data_path = 'data_example/test_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ReadTxtName(train_data_path)\n",
    "test_set = ReadTxtName(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['user_id', 'item_seq_temp','cat_list','time_list','time_last_list','time_now_list','position_list','target','item_seq_len'],data = train_set)\n",
    "test_data = pd.DataFrame(columns=['user_id', 'item_seq_temp','cat_list','time_list','time_last_list','time_now_list','position_list','target','item_seq_len'],data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118873, 190989, 73693, 354311, 73693, 354311,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298668, 297576, 305398, 107015, 32892, 76809,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211347, 153658, 7223, 81509, 19699, 81509, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95057, 68099, 161481, 366635, 150257, 303230,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228127, 202790, 37771, 210693, 316530, 186423...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118873, 190989, 73693, 354311, 73693, 354311,...   \n",
       "1     3839  [298668, 297576, 305398, 107015, 32892, 76809,...   \n",
       "2     3719  [211347, 153658, 7223, 81509, 19699, 81509, 10...   \n",
       "3     4362  [95057, 68099, 161481, 366635, 150257, 303230,...   \n",
       "4     1104  [228127, 202790, 37771, 210693, 316530, 186423...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  \n",
       "0            26  \n",
       "1            23  \n",
       "2            17  \n",
       "3            19  \n",
       "4            18  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-80db74698c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_seq_len'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_seq_len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_seq_temp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_seq_temp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;31m#  will handle complex numbers incorrectly, see GH#32047\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_upcast_putmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "train_data['item_seq_len'] = train_data['item_seq_len']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118873, 190989, 73693, 354311, 73693, 354311,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298668, 297576, 305398, 107015, 32892, 76809,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211347, 153658, 7223, 81509, 19699, 81509, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95057, 68099, 161481, 366635, 150257, 303230,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228127, 202790, 37771, 210693, 316530, 186423...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118873, 190989, 73693, 354311, 73693, 354311,...   \n",
       "1     3839  [298668, 297576, 305398, 107015, 32892, 76809,...   \n",
       "2     3719  [211347, 153658, 7223, 81509, 19699, 81509, 10...   \n",
       "3     4362  [95057, 68099, 161481, 366635, 150257, 303230,...   \n",
       "4     1104  [228127, 202790, 37771, 210693, 316530, 186423...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  \n",
       "0            25  \n",
       "1            22  \n",
       "2            16  \n",
       "3            18  \n",
       "4            17  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['item_seq_temp'] = train_data.item_seq_temp.apply(lambda x:[i+1 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 33308.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_data))):\n",
    "    train_data['item_seq_temp'][i][train_data.item_seq_len[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "input_length = 50\n",
    "train_data['item_seq_temp'] = train_data['item_seq_temp'].apply(lambda x:x+[0]*(input_length-len(x))if len(x)<input_length else x[:input_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 对train_data和test_data进行padding,即item_count+1作为padding_idx\n",
    "# item_id,user_id,cat_list_id进行了重新编码\n",
    "train_data['target_item'] = train_data['target'].apply(lambda x:x[0]) \n",
    "test_data['target_item'] = test_data['target'].apply(lambda x:x[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq_temp</th>\n",
       "      <th>cat_list</th>\n",
       "      <th>time_list</th>\n",
       "      <th>time_last_list</th>\n",
       "      <th>time_now_list</th>\n",
       "      <th>position_list</th>\n",
       "      <th>target</th>\n",
       "      <th>item_seq_len</th>\n",
       "      <th>target_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3522</td>\n",
       "      <td>[118874, 190990, 73694, 354312, 73694, 354312,...</td>\n",
       "      <td>[571, 894, 482, 482, 482, 482, 482, 202, 330, ...</td>\n",
       "      <td>[398008, 398008, 398104, 398104, 398104, 39810...</td>\n",
       "      <td>[0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[125165, 482, 399040]</td>\n",
       "      <td>25</td>\n",
       "      <td>125165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3839</td>\n",
       "      <td>[298669, 297577, 305399, 107016, 32893, 76810,...</td>\n",
       "      <td>[636, 506, 339, 339, 636, 25, 339, 339, 25, 94...</td>\n",
       "      <td>[401704, 401704, 401704, 401704, 401704, 40170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[168523, 943, 401752]</td>\n",
       "      <td>22</td>\n",
       "      <td>168523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3719</td>\n",
       "      <td>[211348, 153659, 7224, 81510, 19700, 81510, 10...</td>\n",
       "      <td>[719, 719, 613, 352, 1333, 352, 352, 1333, 120...</td>\n",
       "      <td>[400216, 400216, 400480, 400552, 400552, 40057...</td>\n",
       "      <td>[0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...</td>\n",
       "      <td>[1008, 1008, 744, 672, 672, 648, 648, 648, 648...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[329307, 344, 401224]</td>\n",
       "      <td>16</td>\n",
       "      <td>329307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>[95058, 68100, 161482, 366636, 150258, 303231,...</td>\n",
       "      <td>[1203, 704, 704, 704, 704, 704, 704, 704, 704,...</td>\n",
       "      <td>[399184, 400192, 400192, 400240, 400240, 40024...</td>\n",
       "      <td>[0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...</td>\n",
       "      <td>[2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[146956, 232, 401704]</td>\n",
       "      <td>18</td>\n",
       "      <td>146956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>[228128, 202791, 37772, 210694, 316531, 186424...</td>\n",
       "      <td>[537, 381, 194, 962, 194, 301, 194, 194, 1098,...</td>\n",
       "      <td>[397672, 397984, 398008, 398536, 398656, 39865...</td>\n",
       "      <td>[0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...</td>\n",
       "      <td>[3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[111155, 67, 401536]</td>\n",
       "      <td>17</td>\n",
       "      <td>111155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      item_seq_temp  \\\n",
       "0     3522  [118874, 190990, 73694, 354312, 73694, 354312,...   \n",
       "1     3839  [298669, 297577, 305399, 107016, 32893, 76810,...   \n",
       "2     3719  [211348, 153659, 7224, 81510, 19700, 81510, 10...   \n",
       "3     4362  [95058, 68100, 161482, 366636, 150258, 303231,...   \n",
       "4     1104  [228128, 202791, 37772, 210694, 316531, 186424...   \n",
       "\n",
       "                                            cat_list  \\\n",
       "0  [571, 894, 482, 482, 482, 482, 482, 202, 330, ...   \n",
       "1  [636, 506, 339, 339, 636, 25, 339, 339, 25, 94...   \n",
       "2  [719, 719, 613, 352, 1333, 352, 352, 1333, 120...   \n",
       "3  [1203, 704, 704, 704, 704, 704, 704, 704, 704,...   \n",
       "4  [537, 381, 194, 962, 194, 301, 194, 194, 1098,...   \n",
       "\n",
       "                                           time_list  \\\n",
       "0  [398008, 398008, 398104, 398104, 398104, 39810...   \n",
       "1  [401704, 401704, 401704, 401704, 401704, 40170...   \n",
       "2  [400216, 400216, 400480, 400552, 400552, 40057...   \n",
       "3  [399184, 400192, 400192, 400240, 400240, 40024...   \n",
       "4  [397672, 397984, 398008, 398536, 398656, 39865...   \n",
       "\n",
       "                                      time_last_list  \\\n",
       "0  [0, 0, 96, 0, 0, 0, 0, 864, 48, 0, 0, 0, 0, 0,...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 264, 72, 0, 24, 0, 0, 0, 24, 24, 288, 0...   \n",
       "3  [0, 1008, 0, 48, 0, 0, 0, 0, 0, 384, 0, 0, 72,...   \n",
       "4  [0, 312, 24, 528, 120, 0, 0, 0, 24, 312, 0, 0,...   \n",
       "\n",
       "                                       time_now_list  \\\n",
       "0  [1032, 1032, 936, 936, 936, 936, 936, 72, 24, ...   \n",
       "1  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
       "2  [1008, 1008, 744, 672, 672, 648, 648, 648, 648...   \n",
       "3  [2520, 1512, 1512, 1464, 1464, 1464, 1464, 146...   \n",
       "4  [3864, 3552, 3528, 3000, 2880, 2880, 2880, 288...   \n",
       "\n",
       "                                       position_list                 target  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [125165, 482, 399040]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [168523, 943, 401752]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [329307, 344, 401224]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [146956, 232, 401704]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   [111155, 67, 401536]   \n",
       "\n",
       "   item_seq_len  target_item  \n",
       "0            25       125165  \n",
       "1            22       168523  \n",
       "2            16       329307  \n",
       "3            18       146956  \n",
       "4            17       111155  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随便padding\n",
    "def pad(data):\n",
    "    for i in data.columns:\n",
    "        if i =='cat_list':\n",
    "            data[i] = data[i].apply(lambda x:x+[x[-1]-1]*(input_length-len(x))if len(x)<input_length else x[:input_length])\n",
    "        elif i=='position_list':\n",
    "            data[i] = data[i].apply(lambda x:[i for i in range(input_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_length = 50\n",
    "pad(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得train_data和test_data\n",
    "columns = ['user_id','item_seq_temp','cat_list','position_list','item_seq_len','target_item']\n",
    "train_data= train_data[columns]\n",
    "test_data = test_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方便处理数据，转换为numpy格式\n",
    "user_id = np.array(train_data['user_id'].tolist(),dtype = np.int32)\n",
    "item_seq_temp = np.array(train_data['item_seq_temp'].tolist(),dtype = np.int32)\n",
    "cat_list = np.array(train_data['cat_list'].tolist(),dtype = np.int32)\n",
    "position_list = np.array(train_data['position_list'].tolist(),dtype = np.int32)\n",
    "item_seq_len = np.array(train_data['item_seq_len'].tolist(),dtype = np.int64)\n",
    "target_item = np.array(train_data['target_item'].tolist(),dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_user_id,x_item_seq_temp,x_cat_list,x_position_list,x_item_seq_len,y,batch_size,shuffle = True):\n",
    "    assert x_user_id.shape[0] == y.shape[0]\n",
    "    if shuffle:\n",
    "        shuffled_index = np.random.permutation(y.shape[0])\n",
    "        x_user_id,x_item_seq_len,x_cat_list,x_position_list,x_item_seq_len = x_user_id[shuffled_index],x_item_seq_len[shuffled_index],x_cat_list[shuffled_index],x_position_list[shuffled_index],x_item_seq_len[shuffled_index]\n",
    "        y = y[shuffled_index]\n",
    "    \n",
    "    n_batches = int(x_user_id.shape[0]/batch_size)\n",
    "    for i in range(n_batches-1):\n",
    "        x_user_id_batch = x_user_id[i*batch_size:(i+1)*batch_size]\n",
    "        x_item_seq_temp_batch = x_item_seq_temp[i*batch_size:(i+1)*batch_size]\n",
    "        x_cat_list_batch = x_cat_list[i*batch_size:(i+1)*batch_size]\n",
    "        x_position_list_batch = x_position_list[i*batch_size:(i+1)*batch_size]\n",
    "        x_item_seq_len_batch = x_item_seq_len[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield x_user_id_batch,x_item_seq_temp_batch,x_cat_list_batch,x_position_list_batch,x_item_seq_len_batch,y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbedding(nn.Module):\n",
    "    def __init__(self,parameter_path,input_length,embedding_dim):\n",
    "        super(GetEmbedding,self).__init__()\n",
    "        self.parameter_path = parameter_path\n",
    "        self.parameters = self.get_parameter(self.parameter_path)\n",
    "        self.user_count = self.parameters['user_count']\n",
    "        self.item_count = self.parameters['item_count']\n",
    "        self.category_count = self.parameters['category_count']\n",
    "        self.input_length = input_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_id_embedding = nn.Embedding(self.user_count+3,self.embedding_dim)\n",
    "        self.item_list_embedding = nn.Embedding(self.item_count+3,self.embedding_dim,padding_idx = 0)\n",
    "        self.item_list_embedding_weight = self.item_list_embedding.weight\n",
    "        self.category_list_embedding = nn.Embedding(self.category_count+3,self.embedding_dim)\n",
    "        self.position_list_embeddig = nn.Embedding(self.input_length,self.embedding_dim)\n",
    "        self.apply(self.init_weights)\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        \n",
    "    def get_parameter(self,file_path):\n",
    "        with open(file_path, 'rb') as f:  \n",
    "            parameters = pickle.loads(f.read())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NARM(nn.Module):\n",
    "    def __init__(self,parameter_path,input_length,embedding_dim,hidden_size,n_layers = 1):\n",
    "        super(NARM,self).__init__()\n",
    "        self.parameter_path = parameter_path\n",
    "        self.input_length = input_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.emb = GetEmbedding(self.parameter_path,self.input_length,self.embedding_dim)\n",
    "        self.emb_dropout = nn.Dropout(0.25)\n",
    "        self.gru = nn.GRU(self.embedding_dim,self.hidden_size,self.n_layers,batch_first = True)\n",
    "        self.a_1 = nn.Linear(self.hidden_size,self.hidden_size,bias = False)\n",
    "        self.a_2 = nn.Linear(self.hidden_size,self.hidden_size,bias = False)\n",
    "        self.v_t = nn.Linear(self.hidden_size,1,bias = False)\n",
    "        self.ct_dropout = nn.Dropout(0.5)\n",
    "        self.b = nn.Linear(self.embedding_dim,2*self.hidden_size,bias = False)\n",
    "        \n",
    "        \n",
    "       \n",
    "    def forward(self,x_item_seq_temp_batch,x_item_seq_len_batch):\n",
    "        item_list_emb = self.emb.item_list_embedding(x_item_seq_temp_batch)\n",
    "        item_list_emb_dropout = self.emb_dropout(item_list_emb)\n",
    "        item_list_emb_nopad = pack_padded_sequence(item_list_emb_dropout,x_item_seq_len_batch,batch_first=True,enforce_sorted=False)\n",
    "        gru_out,hidden = self.gru(item_list_emb_nopad)\n",
    "        gru_out,lengths = pad_packed_sequence(gru_out,batch_first=True,total_length=input_length)\n",
    "        \n",
    "        #fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]#[batch_size,hidden_size]\n",
    "        c_global = ht\n",
    "        \n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1,self.hidden_size)).view(gru_out.size())\n",
    "        q2 = self.a_2(ht)\n",
    "        \n",
    "        mask = torch.where(x_item_seq_temp_batch>0,torch.tensor([1.]),torch.tensor([0.]))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1)*q2_expand\n",
    "        \n",
    "        alpha = self.v_t(torch.sigmoid(q1+q2_masked).view(-1,self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out)*gru_out,1)\n",
    "        \n",
    "        c_t = torch.cat([c_local,c_global],1)\n",
    "        c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        return c_t,self.emb.item_list_embedding_weight\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Myloss,self).__init__()\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "    def forward(self,emb,pred,truth):\n",
    "        item_lookup_table_T = emb.t()\n",
    "        logits = torch.matmul(pred,item_lookup_table_T)\n",
    "        log_probs = self.log_softmax(logits)\n",
    "        truth = torch.reshape(truth,[-1])\n",
    "        one_hot_labels = F.one_hot(truth, num_classes=emb.shape[0])\n",
    "        loss_origin = -torch.sum(log_probs.float() * one_hot_labels.float(), dim=-1)\n",
    "        loss = torch.mean(loss_origin)\n",
    "        return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 12.804776191711426\n",
      "1 0 12.44099235534668\n",
      "2 0 10.49498462677002\n",
      "3 0 10.475838661193848\n",
      "4 0 9.599950790405273\n",
      "5 0 9.551443099975586\n",
      "6 0 7.664181709289551\n",
      "7 0 8.336762428283691\n",
      "8 0 7.855986595153809\n",
      "9 0 7.7232513427734375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-e5d52f95ba5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#         3.梯度更新 w' = w - lr*grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\360downloads\\software\\anaconda3-5.0.1\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "batch_size = 10\n",
    "parameter_path = 'data_example/parameters.pkl'\n",
    "input_length = 50\n",
    "embedding_dim = 32\n",
    "hidden_size=16\n",
    "n_layers = 1\n",
    "narm = NARM(parameter_path,input_length,embedding_dim,hidden_size,n_layers = 1)\n",
    "narm = narm.to(device)\n",
    "narm.train()\n",
    "criterion = Myloss()\n",
    "train_loss = []\n",
    "optimizer = optim.Adam(narm.parameters(),lr=0.001)\n",
    "for epoch in range(10):\n",
    "    for batch_idx,data in enumerate(get_batch(user_id,item_seq_temp,cat_list,position_list,item_seq_len,target_item,batch_size)):\n",
    "        x_user_id_batch = torch.LongTensor(data[0])\n",
    "        x_item_seq_temp_batch = torch.LongTensor(data[1])\n",
    "        x_cat_list_batch = torch.LongTensor(data[2])\n",
    "        x_position_list_batch = torch.LongTensor(data[3])\n",
    "        x_item_seq_len_batch = torch.LongTensor(data[4])\n",
    "        y_batch = torch.LongTensor(data[5])\n",
    "        pred,item_list_emb_weight = narm(x_item_seq_temp_batch,x_item_seq_len_batch)\n",
    "#         print('item_list_emb.shape',item_list_emb_weight.shape)\n",
    "        loss = criterion(item_list_emb_weight,pred,y_batch)\n",
    "        train_loss.append(loss.item())\n",
    "        # Backward and optimizer\n",
    "        # 1.优化器保存先前的梯度信息\n",
    "        optimizer.zero_grad()\n",
    "        # 2.计算梯度\n",
    "        loss.backward()\n",
    "#         3.梯度更新 w' = w - lr*grads\n",
    "        optimizer.step()\n",
    "        if batch_idx%200 == 0:\n",
    "            print(epoch,batch_idx,loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([[1,2,1],[1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = torch.LongTensor([3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = nn.Embedding(3,5,padding_idx = 0)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7515, -1.4493,  0.4747, -0.9737,  0.4582],\n",
       "         [-0.8478,  0.0812,  1.1355, -1.6338,  1.3905],\n",
       "         [-2.7515, -1.4493,  0.4747, -0.9737,  0.4582]],\n",
       "\n",
       "        [[-2.7515, -1.4493,  0.4747, -0.9737,  0.4582],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-2.7515, -1.4493,  0.4747, -0.9737,  0.4582],\n",
       "        [-2.7515, -1.4493,  0.4747, -0.9737,  0.4582],\n",
       "        [-0.8478,  0.0812,  1.1355, -1.6338,  1.3905],\n",
       "        [-2.7515, -1.4493,  0.4747, -0.9737,  0.4582]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb_nopad = pack_padded_sequence(input_emb,seq_len,batch_first=True)\n",
    "input_emb_nopad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size,hidden_size = 5,3\n",
    "gru_output,hidden = nn.GRU(embedding_size,hidden_size,batch_first=True)(input_emb_nopad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.4256,  0.7522,  0.0735],\n",
       "        [-0.4256,  0.7522,  0.0735],\n",
       "        [-0.6064,  0.0024,  0.0175],\n",
       "        [-0.7467,  0.7776,  0.0862]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7467,  0.7776,  0.0862],\n",
       "         [-0.4256,  0.7522,  0.0735]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7467,  0.7776,  0.0862],\n",
       "        [-0.4256,  0.7522,  0.0735]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_output,lengths = pad_packed_sequence(gru_output,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4256,  0.7522,  0.0735],\n",
       "         [-0.6064,  0.0024,  0.0175],\n",
       "         [-0.7467,  0.7776,  0.0862]],\n",
       "\n",
       "        [[-0.4256,  0.7522,  0.0735],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.where(input>0,torch.tensor([1.]),torch.tensor([0.]))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7467,  0.7776,  0.0862],\n",
       "         [-0.7467,  0.7776,  0.0862],\n",
       "         [-0.7467,  0.7776,  0.0862]],\n",
       "\n",
       "        [[-0.4256,  0.7522,  0.0735],\n",
       "         [-0.4256,  0.7522,  0.0735],\n",
       "         [-0.4256,  0.7522,  0.0735]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden:[batch_size,embedding_size]\n",
    "#gru_output:[batch_size,seq_len.embedding_size]\n",
    "\n",
    "hidden_expand = hidden.unsqueeze(1).expand_as(gru_output)\n",
    "hidden_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_masked = mask.unsqueeze(2).expand_as(gru_output)\n",
    "hidden_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7467,  0.7776,  0.0862],\n",
       "         [-0.7467,  0.7776,  0.0862],\n",
       "         [-0.7467,  0.7776,  0.0862]],\n",
       "\n",
       "        [[-0.4256,  0.7522,  0.0735],\n",
       "         [-0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_masked = hidden_masked*hidden_expand\n",
    "hidden_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3909],\n",
       "        [-0.3208],\n",
       "        [-0.4048],\n",
       "        [-0.3747],\n",
       "        [-0.1497],\n",
       "        [-0.1497]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = nn.Linear(hidden_size,1,bias = False)\n",
    "alpha = vt(torch.sigmoid(gru_output+hidden_masked).view(-1,hidden_size))\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3909, -0.3208, -0.4048],\n",
       "        [-0.3747, -0.1497, -0.1497]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = alpha.view(mask.size())\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3909, -0.3909, -0.3909],\n",
       "         [-0.3208, -0.3208, -0.3208],\n",
       "         [-0.4048, -0.4048, -0.4048]],\n",
       "\n",
       "        [[-0.3747, -0.3747, -0.3747],\n",
       "         [-0.1497, -0.1497, -0.1497],\n",
       "         [-0.1497, -0.1497, -0.1497]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = alpha.unsqueeze(2).expand_as(gru_output)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4256,  0.7522,  0.0735],\n",
       "         [-0.6064,  0.0024,  0.0175],\n",
       "         [-0.7467,  0.7776,  0.0862]],\n",
       "\n",
       "        [[-0.4256,  0.7522,  0.0735],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6631, -0.6095, -0.0692],\n",
       "        [ 0.1595, -0.2819, -0.0275]], grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_local = torch.sum(alpha*gru_output,1)\n",
    "c_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
